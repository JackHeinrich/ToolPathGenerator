from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

#LOADS PDF
loader = UnstructuredPDFLoader("C:\\Path\\To\Document\\YourDoc.pdf")
#for online pdf: loader = OnlinePDFLoader("LINK TO PDF")

data = loader.load()

#LETS YOU KNOW HOW LONG PDF IS
print(f'You have {len(data)} document(s) in your data')
print(f'There are {len(data[0].page_content)} characters in your document')

#FOR BREAKING DOWN PDF
text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)

texts = text_splitter.split_documents(data)

#AMOUNT OF PIECES PDF IS BROKEN INTO
print(f'Now you have {len(texts)} document(s) in your data')

from langchain.vectorstores import Pinecone
from langchain.embeddings.openai import OpenAIEmbeddings
import pinecone

#API KEYS
OPENAI_API_KEY = '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'

PINECONE_API_KEY = '4961b180-27ff-42fc-9527-67dedb4132a4'

PINECONE_ENV = 'us-west1-gcp-free'

#OPEN AI TO USE WITH LANGCHAIN TO SEARCH VECTORS
embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)

index_name = "testindex"

#SETS UP INDEX & CLEARS IT
index = pinecone.Index(index_name)

index.delete(delete_all=True)

docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)

from langchain.llms import OpenAI

from langchain.chains.question_answering import load_qa_chain

llm = OpenAI(model_name="text-davinci-003", temperature=0.9, openai_api_key=OPENAI_API_KEY)

# chain = load_qa_chain(llm,chain_type = "stuff", verbose = True)

# query = input("What is your query? ")

from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.agents import Tool

from langchain.agents import AgentType

#TOOL USING PINECONE TO SEARCH DOC
class DocumentSearcher():
    def get_similar_docs(query: str):
        docs = docsearch.similarity_search(query, include_metadata = True)
        final_text = ''
        for doc in docs:
            final_text += doc.page_content
        return(final_text)

tools = load_tools([],llm=llm)

DocumentSearchingTool = Tool("DocumentSearchingTool",DocumentSearcher.get_similar_docs,"Useful for finding information about a question from the document provided")

tools.append(DocumentSearchingTool)

agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)

query = input("What is your query? ")

agent.run(query)

# chain.run(input_documents = docs, question = query)
